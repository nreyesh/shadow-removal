{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ed7bcd-9318-4e3c-b8b0-5b398aec9795",
   "metadata": {},
   "source": [
    "# Unet Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9965d9aa-0aa9-4958-a249-fe0132c9f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                 out_channels=out_channels,\n",
    "                                 kernel_size=(3,3),\n",
    "                                 stride=1,\n",
    "                                 padding=1)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels=out_channels,\n",
    "                                 out_channels=out_channels,\n",
    "                                 kernel_size=(3,3),\n",
    "                                 stride=1,\n",
    "                                 padding=1)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu_2(self.conv2d_2(self.relu_1(self.conv2d_1(x))))   \n",
    "\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_features=[3,64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.encBlock = nn.ModuleList([conv_block(in_features[x],\n",
    "                                                  in_features[x+1]) \n",
    "                                       for x in range(len(in_features)-1)])\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), \n",
    "                                    stride=2, \n",
    "                                    padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encBlock_out = []\n",
    "        for block in self.encBlock:\n",
    "            x = block(x)\n",
    "            encBlock_out.append(x)\n",
    "            x = self.maxpool(x)\n",
    "        return encBlock_out\n",
    "        \n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_features=[512,256,128,64]):\n",
    "        super().__init__()\n",
    "        self.channels = in_features\n",
    "        self.decBlock = nn.ModuleList([conv_block(in_features[x],\n",
    "                                                  in_features[x+1]) \n",
    "                                       for x in range(len(in_features)-1)])\n",
    "        self.upscaling = nn.ModuleList([nn.ConvTranspose2d(in_features[x],\n",
    "                                                  in_features[x+1],\n",
    "                                            kernel_size=(3,3),\n",
    "                                            stride=2,\n",
    "                                            padding=1,\n",
    "                                            output_padding=1) for x in range(len(in_channels)-1)\n",
    "\n",
    "    def forward(self, x, encFeatures):\n",
    "        for i in range(len(self.channels)-1):\n",
    "            x = self.upscaling[i](x)\n",
    "            x = torch.cat(x,encFeat[i])\n",
    "            x = self.decBlock(x)                             \n",
    "        return x\n",
    "        \n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,enc_channels=[3,64,128,256,512],\n",
    "                    dec_channels=[512,256,128,64],\n",
    "                    n_classes = 1,\n",
    "                    out_size=(256,256)):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder_block(enc_channels)\n",
    "        self.decoder = decoder_block(dec_channels)\n",
    "\n",
    "        self.head = nn.Conv2d(dec_channels[-1], n_classes,\n",
    "                             kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.out_size = out_size  \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5041a-6907-4b9b-9615-df91ddff887c",
   "metadata": {},
   "source": [
    "# Testing Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8823ec2f-18e9-4d56-b255-a76614631bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "img = torch.randn(1,3,256,256).to('cuda')\n",
    "conv_block_m = conv_block(3,10).to('cuda')\n",
    "conv_block_m(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6aa27d-04b6-4cdf-af19-a93f40ec1eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 10, 100, 100]             280\n",
      "              ReLU-2         [-1, 10, 100, 100]               0\n",
      "            Conv2d-3         [-1, 10, 100, 100]             910\n",
      "              ReLU-4         [-1, 10, 100, 100]               0\n",
      "================================================================\n",
      "Total params: 1,190\n",
      "Trainable params: 1,190\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 3.05\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 3.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(conv_block_m, (3,100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403f436-d54d-4be7-bc68-354e0e543a98",
   "metadata": {},
   "source": [
    "## Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6b4240-2853-47ae-ae04-ff92b32bc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_block().to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3c70bd-b833-4ff4-83f2-2fdc3090f723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): conv_block(\n",
       "    (conv2d_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_1): ReLU()\n",
       "    (conv2d_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_2): ReLU()\n",
       "  )\n",
       "  (1): conv_block(\n",
       "    (conv2d_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_1): ReLU()\n",
       "    (conv2d_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_2): ReLU()\n",
       "  )\n",
       "  (2): conv_block(\n",
       "    (conv2d_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_1): ReLU()\n",
       "    (conv2d_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_2): ReLU()\n",
       "  )\n",
       "  (3): conv_block(\n",
       "    (conv2d_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_1): ReLU()\n",
       "    (conv2d_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu_2): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40382a0e-7864-42d4-9eec-beb4d339609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 64, 256, 256]),\n",
       " torch.Size([1, 128, 128, 128]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 512, 32, 32])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_enc = encoder(img)\n",
    "[x.shape for x in img_enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e978c2-f221-48e9-84c6-9b591075a83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c0bfee-1e0c-4d18-bd04-6693bb2df384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 100, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = decoder_block(in_channels=10,out_channels=10).to('cuda')\n",
    "decoder(img_enc).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
