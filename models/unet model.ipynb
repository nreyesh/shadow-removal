{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ed7bcd-9318-4e3c-b8b0-5b398aec9795",
   "metadata": {},
   "source": [
    "# Unet Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9965d9aa-0aa9-4958-a249-fe0132c9f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                 out_channels=out_channels,\n",
    "                                 kernel_size=(3,3),\n",
    "                                 stride=1,\n",
    "                                 padding=1)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels=out_channels,\n",
    "                                 out_channels=out_channels,\n",
    "                                 kernel_size=(3,3),\n",
    "                                 stride=1,\n",
    "                                 padding=1)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu_2(self.conv2d_2(self.relu_1(self.conv2d_1(x))))   \n",
    "\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_features=[3,64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.encBlock = nn.ModuleList([conv_block(in_features[x],\n",
    "                                                  in_features[x+1]) \n",
    "                                       for x in range(len(in_features)-1)])\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), \n",
    "                                    stride=2, \n",
    "                                    padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encBlock_out = []\n",
    "        for block in self.encBlock:\n",
    "            x = block(x)\n",
    "            encBlock_out.append(x)\n",
    "            x = self.maxpool(x)\n",
    "        return encBlock_out\n",
    "        \n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_features=[512,256,128,64]):\n",
    "        super().__init__()\n",
    "        self.channels = in_features\n",
    "        self.decBlock = nn.ModuleList([conv_block(in_features[x],\n",
    "                                                  in_features[x+1]) \n",
    "                                       for x in range(len(in_features)-1)])\n",
    "        self.upscaling = nn.ModuleList(nn.ConvTranspose2d(in_features[x],\n",
    "                                                  in_features[x+1],\n",
    "                                            kernel_size=(3,3),\n",
    "                                            stride=2,\n",
    "                                            padding=1,\n",
    "                                            output_padding=1) for x in range(len(in_features)-1))\n",
    "\n",
    "    def forward(self, x, encFeatures):\n",
    "        for i in range(len(self.channels)-1):\n",
    "            #print(f'[INFO]: Iter #{i}')\n",
    "            x = self.upscaling[i](x)\n",
    "            #print(f'Shape Up: {x.shape}')\n",
    "            #print(f'Shape encFeat: {encFeatures[i].shape}')\n",
    "            x = torch.cat([x,encFeatures[i]],dim=1)\n",
    "            #print(f'Shape Concatenation: {x.shape}')\n",
    "            x = self.decBlock[i](x)                             \n",
    "        return x\n",
    "        \n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,enc_channels=[3,64,128,256,512],\n",
    "                    dec_channels=[512,256,128,64],\n",
    "                    n_classes = 1,\n",
    "                    out_size=(256,256)):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder_block(enc_channels)\n",
    "        self.decoder = decoder_block(dec_channels)\n",
    "\n",
    "        self.head = nn.Conv2d(dec_channels[-1], n_classes,\n",
    "                             kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.out_size = out_size  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encFeatures = self.encoder(x)\n",
    "        \n",
    "        decFeatures = self.decoder(encFeatures[::-1][0],encFeatures[::-1][1:])\n",
    "        \n",
    "        classifier = self.head(decFeatures)\n",
    "        \n",
    "        return classifier       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5041a-6907-4b9b-9615-df91ddff887c",
   "metadata": {},
   "source": [
    "# Testing Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8823ec2f-18e9-4d56-b255-a76614631bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 256, 256])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "img = torch.randn(1,3,256,256).to('cuda')\n",
    "conv_block_m = conv_block(3,10).to('cuda')\n",
    "conv_block_m(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c6aa27d-04b6-4cdf-af19-a93f40ec1eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 10, 100, 100]             280\n",
      "              ReLU-2         [-1, 10, 100, 100]               0\n",
      "            Conv2d-3         [-1, 10, 100, 100]             910\n",
      "              ReLU-4         [-1, 10, 100, 100]               0\n",
      "================================================================\n",
      "Total params: 1,190\n",
      "Trainable params: 1,190\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 3.05\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 3.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(conv_block_m, (3,100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403f436-d54d-4be7-bc68-354e0e543a98",
   "metadata": {},
   "source": [
    "## Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc6b4240-2853-47ae-ae04-ff92b32bc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_block().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40382a0e-7864-42d4-9eec-beb4d339609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 64, 256, 256]),\n",
       " torch.Size([1, 128, 128, 128]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 512, 32, 32])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_enc = encoder(img)\n",
    "[x.shape for x in img_enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a862ca-05d1-4e39-bdc6-09feee47c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43685f28-aa90-4eb8-a1f7-a5204b50674a",
   "metadata": {},
   "source": [
    "# Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61c0bfee-1e0c-4d18-bd04-6693bb2df384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder_block(\n",
       "  (decBlock): ModuleList(\n",
       "    (0): conv_block(\n",
       "      (conv2d_1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu_1): ReLU()\n",
       "      (conv2d_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu_2): ReLU()\n",
       "    )\n",
       "    (1): conv_block(\n",
       "      (conv2d_1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu_1): ReLU()\n",
       "      (conv2d_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu_2): ReLU()\n",
       "    )\n",
       "    (2): conv_block(\n",
       "      (conv2d_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu_1): ReLU()\n",
       "      (conv2d_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu_2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (upscaling): ModuleList(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = decoder_block().to('cuda')\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "533a1e41-d763-400b-8147-0a44be4073de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 64, 64])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.upscaling[0](img_enc[-1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c495e8-13bf-4494-aeb0-51bfa8971d3f",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73f42468-a35d-4fed-a72c-6ef3574c4d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): encoder_block(\n",
       "    (encBlock): ModuleList(\n",
       "      (0): conv_block(\n",
       "        (conv2d_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (conv2d_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "      (2): conv_block(\n",
       "        (conv2d_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "      (3): conv_block(\n",
       "        (conv2d_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): decoder_block(\n",
       "    (decBlock): ModuleList(\n",
       "      (0): conv_block(\n",
       "        (conv2d_1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (conv2d_1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "      (2): conv_block(\n",
       "        (conv2d_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_1): ReLU()\n",
       "        (conv2d_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu_2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (upscaling): ModuleList(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (head): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet().to('cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e6427022-6991-4054-8bbd-faa5c3f12081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Iter #0\n",
      "Shape Up: torch.Size([1, 256, 64, 64])\n",
      "Shape encFeat: torch.Size([1, 256, 64, 64])\n",
      "Shape Concatenation: torch.Size([1, 512, 64, 64])\n",
      "[INFO]: Iter #1\n",
      "Shape Up: torch.Size([1, 128, 128, 128])\n",
      "Shape encFeat: torch.Size([1, 128, 128, 128])\n",
      "Shape Concatenation: torch.Size([1, 256, 128, 128])\n",
      "[INFO]: Iter #2\n",
      "Shape Up: torch.Size([1, 64, 256, 256])\n",
      "Shape encFeat: torch.Size([1, 64, 256, 256])\n",
      "Shape Concatenation: torch.Size([1, 128, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = model(img)\n",
    "mask.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
